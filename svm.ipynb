{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "\n",
    "We train a soft margin linear SVM classifier on the data set tumour_samples.csv using 5-fold cross-validation subsets to optimise the hardness hyper-parameter that regulates the boundary violation penalty. We use accuracy as a measure of performance for this\n",
    "hyper-parameter optimisation. We then display the accuracy of the SVM classifiers as the hardness hyper-parameter is varied, and discuss the limits of low hardness and high hardness.\n",
    "\n",
    "We then evaluate the performance of the SVM classifiers obtained as the hardness hyper-parameter is varied by applying each of them to the test data tumour_test.csv. We represent our results using a receiver operating characteristic (ROC) curve. We use the ROC curve to discuss our choice of the optimal hardness hyper-parameter obtained above.\n",
    "\n",
    "We then repeat this for the balanced data set tumour_samples_bal.csv. Using ROC curves (or other measures), we compare and discuss the performance of SVM classifiers learnt from the (unbalanced) data set tumour_samples.csv versus SVM classifiers learnt from the balanced data set tumour_samples_bal.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the data. We dont take the indices column in our predictor variables as well as the DIAGNOSIS column. We standardise the train data and use the same mean and standard deviation to standardise the response test data (we do this because the train data is larger and the estimates of the mean and standard deviation are more reliable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import whole samples data\n",
    "tumour_samples = pd.read_csv(\"tumour_samples.csv\")\n",
    "tumour_samples = tumour_samples.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Import testing data\n",
    "tumour_test = pd.read_csv(\"tumour_test.csv\")\n",
    "tumour_test = tumour_test.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Convert categorical labels to numbers\n",
    "diag_map = {'M': 1.0, 'B': -1.0}\n",
    "\n",
    "# Predictor train data\n",
    "X_tumor_train = tumour_samples.iloc[:,1:-1]\n",
    "# Save the mean and std to standardize the X_tumor_test dataset\n",
    "mu, sigma = np.mean(X_tumor_train, axis = 0), np.std(X_tumor_train, axis = 0)\n",
    "# Standardize\n",
    "X_tumor_train_std = (X_tumor_train - mu) / sigma\n",
    "# Insert intercept column with ones\n",
    "X_tumor_train_std.insert(loc=len(X_tumor_train.columns), column='intercept', value=1)\n",
    "X_tumor_train_std = X_tumor_train_std.to_numpy()\n",
    "\n",
    "# Response train data\n",
    "y_tumor_train = tumour_samples['DIAGNOSIS'].map(diag_map).to_numpy()\n",
    "\n",
    "# Predictor test data\n",
    "X_tumor_test = tumour_test.iloc[:,1:-1]\n",
    "X_tumor_test_std = (X_tumor_test - mu) / sigma\n",
    "X_tumor_test_std.insert(loc=len(X_tumor_test_std.columns), column='intercept', value=1)\n",
    "X_tumor_test_std = X_tumor_test_std.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the hinge loss as\n",
    "$$\n",
    "\\mathcal L (\\boldsymbol w) = \\frac{1}{2} \\| \\boldsymbol w \\|^2 + \\frac{\\lambda}{n} \\sum_{i=1}^n \\max \\bigg( 0, 1-y_i (\\boldsymbol w \\cdot x_i + b) \\bigg) \\, .\n",
    "$$\n",
    "where $\\boldsymbol w$ is the vector of weights, $\\lambda$ the regularisation parameter, and $b$ the intercept which is included in our X as an additional column of $1$'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(w, X, y, regulation_parameter):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    w: vector of weights\n",
    "    X: training features\n",
    "    y: training labels\n",
    "    regulation_parameter: lambda from the loss function\n",
    "    Output:\n",
    "    Computes the hinge loss function.\n",
    "    \"\"\"\n",
    "\n",
    "    distances = 1 - y * (X @ w)\n",
    "    distances[distances < 0] = 0  # equivalent to max(0, distance)\n",
    "    hinge = regulation_parameter * distances.mean()\n",
    "\n",
    "    # Return hinge loss\n",
    "    return 0.5 * np.dot(w, w) + hinge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We optimise this cost by using stochastic gradient descent algorithm. First we implement for the cost gradients with respect to $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost_gradient(w, X_batch, y_batch, regulation_parameter=1e5):\n",
    "    \"\"\"\n",
    "    w: vector of weights\n",
    "    X_batch: a batch of training features\n",
    "    y_barch: vector of training labels corresponding to the X_batch\n",
    "    regulation_parameter: lambda\n",
    "    Output:\n",
    "    Calculate the gradient of the cost.\n",
    "    \"\"\"\n",
    "    \n",
    "    # If only one example is passed\n",
    "    if type(y_batch) == np.float64:\n",
    "        y_batch = np.asarray([y_batch])\n",
    "        X_batch = np.asarray([X_batch])  # gives multidimensional array\n",
    "   \n",
    "    distance = 1 - (y_batch * (X_batch @ w))\n",
    "    dw = np.zeros(len(w))\n",
    "\n",
    "    for ind, d in enumerate(distance):\n",
    "        if max(0, d)==0:\n",
    "            di = w\n",
    "        else:\n",
    "            di = w - (regulation_parameter * y_batch[ind] * X_batch[ind])\n",
    "        dw += di\n",
    "\n",
    "    # Return average\n",
    "    return dw/len(y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the two previous functions are then used in SGD to update the weights iteratively with a given learning rate $\\alpha$. We also implement a stop criterion that ends the learning as soon as the cost function has not changed more than a manually determined percentage.\n",
    "\n",
    "We know that the learning happens through updating the weights according to\n",
    "$$\n",
    "\\boldsymbol w = \\boldsymbol w - \\alpha \\frac{\\partial \\mathcal L}{\\partial \\boldsymbol w}\n",
    "$$\n",
    "\n",
    "where $\\frac{\\partial \\mathcal L}{\\partial \\boldsymbol w}$ is the gradient of the hinge loss we have computed in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(X, y, batch_size=32, max_iterations=2000, stop_criterion=0.01, learning_rate=1e-5, regulation_parameter=1e5):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    X: training features\n",
    "    y: training labels\n",
    "    regulation_parameter: lambda\n",
    "    Output:\n",
    "    Returns the weights w that minimise the cost function.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise zero weights\n",
    "    weights = np.zeros(X.shape[1])\n",
    "    nth = 0\n",
    "\n",
    "    # Initialise starting cost as infinity\n",
    "    prev_cost = np.inf\n",
    "    \n",
    "    # Stochastic gradient descent\n",
    "    indices = np.arange(len(y))\n",
    "    for iteration in range(1, max_iterations):\n",
    "\n",
    "        np.random.shuffle(indices)  # shuffle to prevent repeating update cycles\n",
    "        batch_idx = indices[:batch_size]\n",
    "        X_b, y_b = X[batch_idx], y[batch_idx]\n",
    "\n",
    "        for xi, yi in zip(X_b, y_b):\n",
    "\n",
    "            ascent = calculate_cost_gradient(weights, xi, yi, regulation_parameter)\n",
    "            weights = weights - (learning_rate * ascent)\n",
    "\n",
    "        # Convergence check on 2^n'th iteration\n",
    "        if iteration==2**nth or iteration==max_iterations-1:\n",
    "\n",
    "            # Compute cost\n",
    "            cost = compute_cost(weights, X, y, regulation_parameter)\n",
    "\n",
    "            # Stop criterion\n",
    "            if abs(prev_cost - cost) < stop_criterion * prev_cost:\n",
    "                \n",
    "                return weights\n",
    "              \n",
    "            prev_cost = cost\n",
    "            nth += 1\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform a 5-fold cross-validation search for the optimal regulation_parameter. We proceed as before, first we create a score function and then we create a cross_validation_score_svm function which evaluates the average score over 5-fold cross-validation for a given regulation_parameter. Then we create a function which loops over a given range for the regulation_parameter and returns the parameter which gives the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_svm(w, X, y):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    w: weights\n",
    "    X: test features\n",
    "    y: test true lables\n",
    "    Outpu:\n",
    "    Returns the accuracy of the model for given weights w.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute predictions\n",
    "    y_preds = np.sign(X @ w)\n",
    "    \n",
    "    # Return accuracy\n",
    "    return np.mean(y_preds == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_score_svm(X, y, folds, regulation_parameter):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    X: training inputs\n",
    "    y: training responses\n",
    "    folds: the 5 folds for cross-validatiom\n",
    "    regulation_parameter: lambda\n",
    "    Output:\n",
    "    Return the average score over 5-fold cross-validation.\n",
    "    \"\"\"\n",
    "\n",
    "    validation_scores = []\n",
    "    \n",
    "    for i in range(len(folds)):\n",
    "\n",
    "        # Define the training and validation indices\n",
    "        validation_indices = folds[i]\n",
    "        training_indices = list(set(range(X.shape[0])) - set(validation_indices))\n",
    "\n",
    "        # Define training sets\n",
    "        X_train = X[training_indices]\n",
    "        y_train = y[training_indices]\n",
    "        \n",
    "        # Define validation sets\n",
    "        X_val = X[validation_indices]  \n",
    "        y_val = y[validation_indices] \n",
    "\n",
    "        # Train the model\n",
    "        w = sgd(X_train, \n",
    "                y_train,\n",
    "                max_iterations=1025,\n",
    "                stop_criterion=0.01,\n",
    "                learning_rate=1e-5,\n",
    "                regulation_parameter=regulation_parameter)\n",
    "        \n",
    "        # Evaluate\n",
    "        validation_score = score_svm(w, X_val, y_val)\n",
    "        validation_scores.append(validation_score)\n",
    "\n",
    "    return np.mean(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_regulation_parameter(X_train, y_train, folds, regulation_parameter_range):\n",
    "  \"\"\"\n",
    "  Input:\n",
    "  X_train: training inputs\n",
    "  y_train: training responses\n",
    "  folds: the 5 folds for the cross-validation\n",
    "  regulation_parameter_range: range of values for lambda\n",
    "  Output:\n",
    "  Returns the regulation_parameter which has the highest accuracy.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Initialize scores\n",
    "  scores = np.zeros(len(regulation_parameter_range))\n",
    "\n",
    "  # Compute score for each regulation_parameter\n",
    "  for i, regulation_parameter in enumerate(regulation_parameter_range):\n",
    "    scores[i] = cross_validation_score_svm(X_train, \n",
    "                                           y_train,\n",
    "                                           folds,\n",
    "                                           regulation_parameter)\n",
    "  \n",
    "  # Return the optimal regulation_parameter, a list with all scores and the optimal score\n",
    "  return regulation_parameter_range[np.argmax(scores)], scores, scores[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(N, num_folds):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    N: length of dataset\n",
    "    num_folds: number of folds xD\n",
    "    Output:\n",
    "    Splits the data into folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    fold_size = N // num_folds\n",
    "    index_perm = np.random.permutation(np.arange(N))\n",
    "    folds = []\n",
    "    for k in range(num_folds):\n",
    "        folds.append(index_perm[k*fold_size:(k+1)*fold_size])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fix a range for the hyper-parameter and use our function to find its optimal value. We create our range to include first a set of smaller values and then a set of larger values for better visual output later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set range for the hyper-parameter\n",
    "regulation_parameter_range = np.append(np.linspace(0,20,20), np.linspace(500,1000,50))\n",
    "\n",
    "# Create folds\n",
    "folds = cross_validation_split(X_tumor_train_std.shape[0], num_folds=5)\n",
    "\n",
    "# Compute the optimal parameter and store all scores\n",
    "optimal_regulation_parameter, scores, optimal_score = choose_best_regulation_parameter(X_tumor_train_std,\n",
    "                                                                                       y_tumor_train,\n",
    "                                                                                       folds,\n",
    "                                                                                       regulation_parameter_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimal_regulation_parameter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\OneDrive\\Documents\\Desktop\\Python\\kNN-Random-Forests-and-SVM-from-Scratch\\svm.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Print the optimal hyper-parameter\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOptimal hyper-parameter: \u001b[39m\u001b[39m\"\u001b[39m, optimal_regulation_parameter)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMean accuracy for the optimal parameter: \u001b[39m\u001b[39m\"\u001b[39m, optimal_score)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimal_regulation_parameter' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the optimal hyper-parameter\n",
    "print(\"Optimal hyper-parameter: \", optimal_regulation_parameter)\n",
    "print(\"Mean accuracy for the optimal parameter: \", optimal_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we return an optimal value of the hyper-parameter, we create a plot of the accuracy vs different parameters and notice that for high values of the parameter, the accuracy is very close to $1$, and it is lower only for low values of the hyper-parameter. Hence we can consider any large enough hardness parameter as a good fit for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.plot(regulation_parameter_range[1:], scores[1:])\n",
    "plt.title(\"Accuracy for different values of the hyper-parameter\", size=20)\n",
    "plt.xlabel(\"Hyper-parameter\", size=20)\n",
    "plt.ylabel(\"Score\", size=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plot the accuracy for the smaller set of values for the hyper-parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.plot(regulation_parameter_range[1:20], scores[1:20])\n",
    "plt.title(\"Accuracy for different values of the hyper-parameter\", size=20)\n",
    "plt.xlabel(\"Hyper-parameter\", size=20)\n",
    "plt.ylabel(\"Score\", size=20)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Print score for zero hyper-parameter\n",
    "print(\"For zero hyper parameter we get an accuracy of: \", scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now discuss the variability of the accuracy as we change the hyper-parameter. On the plot we show the accuracy for different lambda. \n",
    "\n",
    "If we imagine the $2D$ case, this corresponds to the two classes being separated by a 'road' where we want the width of the road to be maximal and we also want as many as possible of the points to be correctly classified. \n",
    "\n",
    "When the hyper-parameter is relatively high, we put most of the weight of the hinge loss function on the constraint which penalises wrongly classified points. This means that the width of the 'road' is of little to no importance as we increase $\\lambda$ and in the limit, we approach the case of hard-margin SVM where we attempt to draw a line (in $2D$ case) with zero width separating the two classes (although it is not always possible to perfectly separate the two classes, but in our case we seem to be very close to do so as the accuracy is very close to $1$).\n",
    "\n",
    "For low values of the hyper-parameter, we put bigger weight on the width of the 'road' at the expense of the amount of wrongly classified points. As $\\lambda$ goes to zero, we put the entire weight on the width and disregard how many points are wrongly classified, hence we get very low accuracy. For our data, we see that the width of the road is of very low importance as we get higher accuracies for large $\\lambda$. To avoid overfitting the model however, we need to consider the tumour_test.csv dataset as we do in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate the performance of the model on the tumour_test.csv dataset. First we calculate the weights from the train data with the optimal value of lambda found above and use it to compute the accuracy on the test data that we have not used so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response test data\n",
    "diag_map = {'M': 1.0, \"B\": -1.0}\n",
    "y_tumor_test = tumour_test['DIAGNOSIS'].map(diag_map).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sgd(X_tumor_train_std, \n",
    "        y_tumor_train,\n",
    "        max_iterations=1025,\n",
    "        stop_criterion=0.01,\n",
    "        learning_rate=1e-5,\n",
    "        regulation_parameter=optimal_regulation_parameter)\n",
    "\n",
    "print(\"Accuracy on tain data: \", optimal_score)\n",
    "print(\"Accuracy on test data: \", score_svm(w, X_tumor_test_std, y_tumor_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy is very high and similar to the optimal score on the train data from the previous section, which suggests that our model did not overfit. \n",
    "\n",
    "Next, we plot a ROC curve using the function below taken from the Logistic Regression coding task and slightly modified. For our thresholds, we use the quantity $X @ w$ as if this is close to zero (i.e. a point is close to the line separating the two classifications) then it is likely that it is wrongly classified. By that we mean that the farther away a point is from the line (i.e. the farther away $X @ w$ is from $0$) the larger the probability that we have correctly classified that point. So $X @ w$ could be interpreted as the equivalent of the probabilities in the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response test data\n",
    "diag_map = {'M': 1, \"B\": 0}\n",
    "y_tumor_test = tumour_test['DIAGNOSIS'].map(diag_map).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve(y_test, y_prediction_svm):\n",
    "  \"\"\"\n",
    "  Arguments:\n",
    "  y_test: ground truth labels\n",
    "  y_prediction_svm: values produced by svm model\n",
    "  \n",
    "  Returns:\n",
    "  AUC: area under the curve.\n",
    "  TPR_values: a list of true positive rate (TPR) values for each scanned threshold.\n",
    "  FPR_values: a list of false positive rate (FPR) values for each scanned threshold.\n",
    "  \"\"\"\n",
    "  # List of distinct values in y_prediction_svm, sorted descendingly.\n",
    "  thresholds = reversed(sorted(set(y_prediction_svm))) \n",
    "  TPR_values, FPR_values = [], []\n",
    "\n",
    "  for threshold in thresholds:\n",
    "    # Apply thresholding\n",
    "    y_thresholded = (y_prediction_svm >= threshold)\n",
    "\n",
    "    # True positives\n",
    "    TP = np.sum(y_test & y_thresholded)\n",
    "    # True negatives\n",
    "    TN = np.sum((~y_test) & (~y_thresholded))\n",
    "    # False positives\n",
    "    FP = np.sum((~y_test) & y_thresholded)\n",
    "    # False negatives\n",
    "    FN = np.sum(y_test & (~y_thresholded))\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (TN + FP)\n",
    "    TPR_values.append(TPR)\n",
    "    FPR_values.append(FPR)\n",
    "\n",
    "  # Compute AUC using Trapezoidal rule\n",
    "  AUC = np.trapz(TPR_values, FPR_values)\n",
    "\n",
    "  return TPR_values, FPR_values, AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a function that plots the ROC curves for a given value of the hyper-parameter. We compute the weights using our Stochastic Gradient Descent function and then we create a plot of TPR vs FPR for each hyper-parameter in a given range. We return the area under the curve (AUC) values since we plot them as well afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(X_train, y_train, X_test, y_test, regulation_parameter_range):\n",
    "    \"\"\"Plot ROC curves for a range of hyper-parameters and returns the AUC values.\"\"\"\n",
    "\n",
    "    # store AUC values\n",
    "    AUC_values = []\n",
    "\n",
    "    # colors for plots\n",
    "    colors = plt.cm.jet(np.linspace(0, 1, 100))\n",
    "\n",
    "    for regulation_parameter, c in zip(regulation_parameter_range, colors):\n",
    "        \n",
    "        # compute weights for a given hyper-parameter\n",
    "        w = sgd(X_train, y_train,\n",
    "                max_iterations=1025,\n",
    "                stop_criterion=0.01,\n",
    "                learning_rate=1e-5,\n",
    "                regulation_parameter=regulation_parameter)\n",
    "    \n",
    "        # compute predictions for thresholding\n",
    "        y_predictions = X_test @ w\n",
    "\n",
    "        TPR, FPR, AUC = roc_curve(y_test, y_predictions)\n",
    "        \n",
    "        AUC_values.append(AUC)\n",
    "\n",
    "        # plot\n",
    "        plt.plot(FPR, TPR, color = c)\n",
    "    \n",
    "    return AUC_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create the plot. The curves are all above the diagonal line, which means that the model is doing better than a completely random classifier (under the diagonal line the model would be doing worse than random). For small values of the hyper-parameter the model is doing worse than for larger values, where we see that it approaches the corner $FPR = 0$ and $TPR = 1$. \n",
    "\n",
    "We have also created a plot of the area under the curve as the hyper-parameter changes. It is an overall measure of the quality of the model, and we would want to see that the AUC is greater than $0.5$ meaning that the model is performing better than random. Once again, as the hyper-parameter increases the AUC is very close to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set range for the hyper-parameter\n",
    "regulation_parameter_range = np.linspace(1,100,100)\n",
    "\n",
    "# plot receiver operating characteristic curves\n",
    "plt.figure(figsize=(25,10))\n",
    "AUC_values = plot_roc_curves(X_tumor_train_std, \n",
    "                             y_tumor_train,\n",
    "                             X_tumor_test_std,\n",
    "                             y_tumor_test,\n",
    "                             regulation_parameter_range = regulation_parameter_range)\n",
    "plt.plot([0, 1], [0, 1], 'C0--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.title(f\"Receiver Operating Curve\", size=20)\n",
    "plt.ylabel('TPR', size=20)\n",
    "plt.xlabel('FPR', size=20)\n",
    "plt.show()\n",
    "\n",
    "# plot AUC values\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.plot(regulation_parameter_range, AUC_values)\n",
    "plt.title(\"AUC for different hyper-parameters\", size=20)\n",
    "plt.xlabel(\"Hyper-parameter\", size=20)\n",
    "plt.ylabel(\"AUC\", size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, as the hyper-parameter increases so does our accuracy and the AUC. For large enough lambda we see that the AUC is very close to 1 and on the ROC curve this is represented by the red-colored curves, which approach the corner (0,1) as expected, while for lower values of lambda we are closer to the diagonal line. Due to the stochastic nature of the model, the choice of the hyper-parameter will vary, but it is important to note that the larger value of lambda we have, the more accurate our model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now work with the balanced tumour dataset. As before, we standardise and use the mean and standard deviation to standardise the test set, map the categorical labels to $1$ and $-1$. We also insert an intercept column of ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_map = {'M': 1.0, 'B': -1.0}\n",
    "tumour_samples_bal = pd.read_csv('tumour_samples_bal.csv')\n",
    "tumour_samples_bal['DIAGNOSIS'] = tumour_samples_bal['DIAGNOSIS'].map(diag_map)\n",
    "\n",
    "# Predictor data\n",
    "X_tumor_train_bal = tumour_samples_bal.iloc[:, 1: -1]\n",
    "mu, sigma = np.mean(X_tumor_train_bal, axis = 0), np.std(X_tumor_train_bal, axis = 0)  # save the mean and std to standardize the X_tumor_test dataset\n",
    "X_tumor_train_bal_std = (X_tumor_train_bal - mu) / sigma  # standardize\n",
    "X_tumor_train_bal_std.insert(loc=len(X_tumor_train_bal_std.columns), column='intercept', value=1)  # insert intercept column with ones\n",
    "X_tumor_train_bal_std = X_tumor_train_bal_std.to_numpy()\n",
    "\n",
    "# Response data\n",
    "y_tumor_train_bal = tumour_samples_bal.loc[:, \"DIAGNOSIS\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform 5-fold cross validation to find the optimal hyper-parameter with the balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\OneDrive\\Documents\\Desktop\\Python\\kNN-Random-Forests-and-SVM-from-Scratch\\svm.ipynb Cell 38\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m folds \u001b[39m=\u001b[39m cross_validation_split(X_tumor_train_bal_std\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], num_folds\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# compute the optimal parameter and store all scores\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m optimal_regulation_parameter_bal, scores_bal, optimal_score_bal \u001b[39m=\u001b[39m choose_best_regulation_parameter(X_tumor_train_bal_std,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                                                                                    y_tumor_train_bal,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                                                                                    folds,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                                                                                    regulation_parameter_range)\n",
      "\u001b[1;32mc:\\Users\\Admin\\OneDrive\\Documents\\Desktop\\Python\\kNN-Random-Forests-and-SVM-from-Scratch\\svm.ipynb Cell 38\u001b[0m in \u001b[0;36mchoose_best_regulation_parameter\u001b[1;34m(X_train, y_train, folds, regulation_parameter_range)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Compute score for each regulation_parameter\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, regulation_parameter \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(regulation_parameter_range):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m   scores[i] \u001b[39m=\u001b[39m cross_validation_score_svm(X_train, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                                          y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                                          folds,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                                          regulation_parameter)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Return the optimal regulation_parameter, a list with all scores and the optimal score\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mreturn\u001b[39;00m regulation_parameter_range[np\u001b[39m.\u001b[39margmax(scores)], scores, scores[np\u001b[39m.\u001b[39margmax(scores)]\n",
      "\u001b[1;32mc:\\Users\\Admin\\OneDrive\\Documents\\Desktop\\Python\\kNN-Random-Forests-and-SVM-from-Scratch\\svm.ipynb Cell 38\u001b[0m in \u001b[0;36mcross_validation_score_svm\u001b[1;34m(X, y, folds, regulation_parameter)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m y_val \u001b[39m=\u001b[39m y[validation_indices] \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m w \u001b[39m=\u001b[39m sgd(X_train, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         max_iterations\u001b[39m=\u001b[39;49m\u001b[39m1025\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         stop_criterion\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-5\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         regulation_parameter\u001b[39m=\u001b[39;49mregulation_parameter)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Evaluate\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m validation_score \u001b[39m=\u001b[39m score_svm(w, X_val, y_val)\n",
      "\u001b[1;32mc:\\Users\\Admin\\OneDrive\\Documents\\Desktop\\Python\\kNN-Random-Forests-and-SVM-from-Scratch\\svm.ipynb Cell 38\u001b[0m in \u001b[0;36msgd\u001b[1;34m(X, y, batch_size, max_iterations, stop_criterion, learning_rate, regulation_parameter)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m batch_idx \u001b[39m=\u001b[39m indices[:batch_size]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m X_b, y_b \u001b[39m=\u001b[39m X[batch_idx], y[batch_idx]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m xi, yi \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39;49m(X_b, y_b):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     ascent \u001b[39m=\u001b[39m calculate_cost_gradient(weights, xi, yi, regulation_parameter)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/Documents/Desktop/Python/kNN-Random-Forests-and-SVM-from-Scratch/svm.ipynb#X56sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     weights \u001b[39m=\u001b[39m weights \u001b[39m-\u001b[39m (learning_rate \u001b[39m*\u001b[39m ascent)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set range for the hyper-parameter\n",
    "regulation_parameter_range = np.append(np.linspace(0,20,20), np.linspace(500,1000,50))\n",
    "\n",
    "#create folds\n",
    "folds = cross_validation_split(X_tumor_train_bal_std.shape[0], num_folds=5)\n",
    "\n",
    "# compute the optimal parameter and store all scores\n",
    "optimal_regulation_parameter_bal, scores_bal, optimal_score_bal = choose_best_regulation_parameter(X_tumor_train_bal_std,\n",
    "                                                                                                   y_tumor_train_bal,\n",
    "                                                                                                   folds,\n",
    "                                                                                                   regulation_parameter_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the optimal hyper-parameter for the balanced dataset\n",
    "print(\"Optimal balanced hyper-parameter: \", optimal_regulation_parameter_bal)\n",
    "print(\"Mean accuracy for the balanced optimal parameter: \", optimal_score_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.plot(regulation_parameter_range[1:], scores_bal[1:])\n",
    "plt.title(\"Accuracy for different values of the hyper-parameter\", size=20)\n",
    "plt.xlabel(\"Hyper-parameter\", size=20)\n",
    "plt.ylabel(\"Score\", size=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we also create a plot only for the smaller values of the hyper-parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.plot(regulation_parameter_range[1:20], scores_bal[1:20])\n",
    "plt.title(\"Accuracy for different values of the hyper-parameter\", size=20)\n",
    "plt.xlabel(\"Hyper-parameter\", size=20)\n",
    "plt.ylabel(\"Score\", size=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison to the imbalanced dataset, we notice that for larger values of lambda there appears to be more variablility in the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set range for the hyper-parameter\n",
    "regulation_parameter_range = np.linspace(1,100,100)\n",
    "\n",
    "# plot receiver operating characteristic curves\n",
    "plt.figure(figsize=(25,10))\n",
    "AUC_values = plot_roc_curves(X_tumor_train_bal_std, \n",
    "                             y_tumor_train_bal,\n",
    "                             X_tumor_test_std,\n",
    "                             y_tumor_test,\n",
    "                             regulation_parameter_range = regulation_parameter_range)\n",
    "plt.plot([0, 1], [0, 1], 'C0--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.title(f\"Receiver Operating Curve\", size=20)\n",
    "plt.ylabel('TPR', size=20)\n",
    "plt.xlabel('FPR', size=20)\n",
    "plt.show()\n",
    "\n",
    "# plot AUC values\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.plot(regulation_parameter_range, AUC_values)\n",
    "plt.title(\"AUC for different hyper-parameters\", size=20)\n",
    "plt.xlabel(\"Hyper-parameter\", size=20)\n",
    "plt.ylabel(\"AUC\", size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare the balanced and imbalanced datasets. From the ROC curves, we can see that the balanced dataset performs better for smaller values of the hyper-parameter and similar to the imbalanced dataset converges to the corner $(0,1)$. The plot on the accuracy however shows that for larger lambdas, there is more variablility in the accuracy of the balanced dataset, however this may be because of the stochastic nature of our model (and we may need to increase number of iterations in our sgd function). \n",
    "\n",
    "In the balanced dataset we lose information on the frequency of events (in our case the frequency of malignant tumors), which is worth mentioning as it may affect our preference on a dataset depending on what information we need."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58dbfdb34cf82127b32c5737e6183911655ff227e5c11e8f5e4b25048ae98ef2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
